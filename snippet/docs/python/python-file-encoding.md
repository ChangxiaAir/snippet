## Python文件编码

### 一、预备知识
#### 1、字符
字符是抽象的最小文本单位。它没有固定的形状（可能是一个字形），而且没有值。“A”是一个字符，“”（德国、法国和许多其他欧洲国家通用货币的标志）也是一个字符。“中”“国”这是两个汉字字符。字符仅仅代表一个符号，没有任何实际值的意义。

#### 2、字符集
字符集是字符的集合。例如，汉字字符是中国人最先发明的字符，在中文、日文、韩文和越南文的书写中使用。这也说明了字符和字符集之间的关系，字符组成字符集（iso8859-1，GB2312/GBK，unicode）。

#### 3、代码点
字符集中的每个字符都被分配到一个 `代码点`。每个代码点都有一个特定的唯一数值，称为 `标值`。该标量值通常用 `十六进制` 表示。

#### 4、代码单元
在每种编码形式中，代码点被映射到一个或多个代码单元。`代码单元` 是各个编码方式中的单个单元。代码单元的大小等效于特定编码方式的位数：

##### UTF-8
UTF-8 中的代码单元由 8 位组成；在 UTF-8 中，因为代码单元较小的缘故，每个代码点常常被映射到多个代码单元。代码点将被映射到一个、两个、三个或四个代码单元；

##### UTF-16
UTF-16 中的代码单元由 16 位组成；UTF-16 的代码单元大小是 8 位代码单元的两倍。所以，标量值小于 U+10000 的代码点被编码到单个代码单元中。

##### UTF-32
UTF-32 中的代码单元由 32 位组成；UTF-32 中使用的 32 位代码单元足够大，每个代码点都可编码为单个代码单元。

##### GB18030
GB18030 中的代码单元由 8 位组成；在 GB18030 中，因为代码单元较小的缘故，每个代码点常常被映射到多个代码单元。代码点将被映射到一个、两个或四个代码单元。

#### 5、举例
`中国北京香蕉是个大笨蛋` 这是我定义的 aka 字符集；各字符对应 `代码点` 为：
```
北 00000001
京 00000010
香 10000001
蕉 10000010
是 10000100
个 10001000
大 10010000
笨 10100000
蛋 11000000
中 00000100
国 00001000
```

下面是我定义的 zixia 编码方案（8位），可以看到它的编码中表示了 aka 字符集的所有字符对应的 `代码单元`：
```
北 10000001
京 10000010
香 00000001
蕉 00000010
是 00000100
个 00001000
大 00010000
笨 00100000
蛋 01000000
中 10000100
国 10001000
```

所谓 `文本文件` 就是我们按一定编码方式将二进制数据表示为对应的文本如 `00000001000000100000010000001000000100000010000001000000` 这样的文件。用一个支持 zixia 编码和 aka 字符集的记事本打开，它就按照编码方案显示为 `香蕉是个大笨蛋`。

如果我把这些字符按照 GBK 另存一个文件，那么则肯定不是这个，而是 `1100111111100011 1011110110110110 1100101011000111 1011100011110110 1011010011110011 1011000110111111 1011010110110000 110100001010`。


### 二、字符集
#### 1、常用字符集分类
##### `ASCII` 及其扩展字符集
作用：表语英语及西欧语言。
位数：ASCII是用7位表示的，能表示128个字符；其扩展使用8位表示，表示256个字符。
范围：ASCII从00到7F，扩展从00到FF。

##### `ISO-8859-1` 字符集
**作用：**扩展ASCII，表示西欧、希腊语等。

**位数：**8位，

**范围：**从00到FF，兼容ASCII字符集。

##### `GB2312` 字符集
**作用：**国家简体中文字符集，兼容ASCII。

**位数：**使用2个字节表示，能表示7445个符号，包括6763个汉字，几乎覆盖所有高频率汉字。

**范围：**高字节从A1到F7, 低字节从A1到FE。将高字节和低字节分别加上0XA0即可得到编码。

##### `BIG5` 字符集
**作用：**统一繁体字编码。

**位数：**使用2个字节表示，表示13053个汉字。

**范围：**高字节从A1到F9，低字节从40到7E，A1到FE。

##### `GBK` 字符集
**作用：**它是GB2312的扩展，加入对繁体字的支持，兼容GB2312。

**位数：**使用2个字节表示，可表示21886个字符。

**范围：**高字节从81到FE，低字节从40到FE。

##### `GB18030` 字符集
**作用：**它解决了中文、日文、朝鲜语等的编码，兼容GBK。

**位数：**它采用变字节表示(1 ASCII，2，4字节)。可表示27484个文字。

**范围：**1字节从00到7F; 2字节高字节从81到FE，低字节从40到7E和80到FE；4字节第一三字节从81到FE，第二四字节从30到39。

##### `UCS` 字符集
**作用：**国际标准 ISO 10646 定义了通用字符集 (Universal Character Set)。它是与UNICODE同类的组织，UCS-2和UNICODE兼容。

**位数：**它有 `UCS-2` 和 `UCS-4` 两种格式，分别是2字节和4字节。

**范围：**目前，UCS-4只是在UCS-2前面加了0×0000。

##### `UNICODE` 字符集
**作用：**为世界650种语言进行统一编码，兼容ISO-8859-1。

**位数：**UNICODE字符集有多个编码方式，分别是`UTF-8`、`UTF-16` 和 `UTF-32`。

#### 2、按所表示的文字分类

语言                |      字符集         |     正式名称
--------------------|---------------------|---------------------
英语、西欧语        |  ASCII，ISO-8859-1  |  MBCS 多字节
简体中文            |  GB2312             |  MBCS 多字节
繁体中文            |  BIG5               |  MBCS 多字节
简繁中文            |  GBK                |  MBCS 多字节
中文、日文及朝鲜语  |  GB18030            |  MBCS 多字节
各国语言            |  UNICODE，UCS       |  DBCS 宽字节


### 三、编码
#### 1、UTF-8
采用变长字节 (1 ASCII, 2 希腊字母, 3 汉字, 4 平面符号) 表示，网络传输, 即使错了一个字节，不影响其他字节，而双字节只要一个错了，其他也错了，具体如下：如果只有一个字节则其最高二进制位为0；如果是多字节，其第一个字节从最高位开始，连续的二进制位值为 1 的个数决定了其编码的字节数，其余各字节均以 `10` 开头。UTF-8 最多可用到 6 个字节。

UTF-8 编码分为六个区：
```
一区为单字节编码，
　　编码格式为：0xxxxxxx；
　　对应Unicode：0x0000 - 0x007f
二区为双字节编码，
　　编码格式为：110xxxxx 10xxxxxx；
　　对应Unicode：0x0080 - 0x07ff
三区为三字节编码，
　　编码格式为：1110xxxx 10xxxxxxx 10xxxxxx
　　对应Unicode：0x0800 - 0xffff
四区为四字节编码，
　　编码格式为：11110xxx 10xxxxxxx 10xxxxxx 10xxxxxx
　　对应Unicode：0x00010000 - 0x0001ffff
五区为五字节编码，
　　编码格式为：111110xx 10xxxxxxx 10xxxxxxx 10xxxxxxx 10xxxxxxx
　　对应Unicode：0x00200000 - 0x03ffffff
六区为六字节编码，
　　编码格式为：111110x 10xxxxxxx 10xxxxxxx 10xxxxxxx 10xxxxxxx 10xxxxxxx
　　对应Unicode：0x04000000 - 0x7fffffff
```

#### 2、UTF-16
采用 2 字节，Unicode中不同部分的字符都同样基于现有的标准。这是为了便于转换。从 `0×0000` 到 `0×007F` 是 ASCII 字符，从 `0×0080` 到 `0×00FF` 是 ISO-8859-1 对 ASCII 的扩展。希腊字母表使用从 `0×0370` 到 `0×03FF` 的代码，斯拉夫语使用从 `0×0400` 到 `0×04FF` 的代码，美国使用从 `0×0530` 到 `0×058F` 的代码，希伯来语使用从 `0×0590` 到 `0×05FF` 的代码。中国、日本和韩国的象形文字（总称为`CJK`）占用了从 `0×3000` 到 `0×9FFF` 的代码；由于 `0×00` 在c语言及操作系统文件名等中有特殊意义，故很 多情况下需要 UTF-8 编码保存文本，去掉这个 `0×00`。

举例如下：
```
UTF-16: 0×0080  = 0000 0000 1000 0000
UTF-8:  0xC280 = 1100 0010 1000 0000
UTF-32：采用4字节。
```

#### 3、优缺点
`UTF-8`、`UTF-16` 和 `UTF-32` 都可以表示有效编码空间 (`U+000000` - `U+10FFFF`) 内的所有 Unicode 字符。使用UTF-8编码时ASCII字符只占1个字节，存储效率比较高，适用于拉丁字符较多的场合以节省空间。对于大多数非拉丁字符（如中文和日文）来说，UTF-16所需存储空间最小，每个字符只占2个字节。Windows NT内核是Unicode（UTF-16），采用UTF-16编码在调用系统API时无需转换，处理速度也比较快。采用UTF-16和UTF-32会有Big Endian和Little Endian之分，而UTF-8则没有字节顺序问题，所以UTF-8适合传输和通信。UTF-32采用4字节编码，一方面处理速度比较快，但另一方面也浪费了大量空间，影响传输速度，因而很少使用。

### 四、如何判断字符集
#### 1、字节序
首先说一下字节序对编码的影响，字节序分为 Big Endian 字节序和 Little Endian 字节序。不同的处理器可能不一样。所以，传输时需要告诉处理器当时的编码字节序。对于前者而言，高位字节存在低地址，低字节存于高地址；后者相反。

例如，0X03AB,
```
Big Endian字节序
0000: 03
0001: AB

Little Endian字节序是
0000: AB
0001: 03
```
#### 2、编码识别
##### Unicode
根据前几个字节可以判断 unicode 字符集的各种编码，叫做 `Byte Order Mask` 方法（简称 `BOM`）：
```
UTF-8: EFBBBF (符合 UTF-8 格式，请看上面。但没有含义在 UCS 即 UNICODE 中)
UTF-16 Big Endian：FEFF (没有含义在 UCS-2 中)
UTF-16 Little Endian：FFFE (没有含义在 UCS-2 中)
UTF-32 Big Endian：0000FEFF (没有含义在 UCS-4 中)
UTF-32 Little Endian：FFFE0000 (没有含义在 UCS-4 中)
```

##### GB2312
高字节和低字节的第 1 位都是 1。

###### BIG5, GBK & GB18030
高字节的第 1 位为 1。操作系统有默认的编码，常为 GBK，可以下载别的并升级。通过判断高字节的第 1 位从而知道是 ASCII 或者汉字编码。


### 五、Python与字符编码

ASCII 是一种字符集,包括大小写的英文字母、数字、控制字符等，它用一个字节表示，范围是 0-127。

Unicode 分为 UTF-8 和 UTF-16 。UTF-8 变长度的，最多 6 个字节，小于 127 的字符用一个字节表示，与 ASCII 字符集的结果一样，ASCII 编码下的英语文本不需要修改就可以当作 UTF-8 编码进行处理。

Python 从 2.2 开始支持 Unicode ，函数 `decode(char_set)` 可以实现其它编码到 Unicode 的转换，函数 `encode(char_set)` 实现 Unicode 到其它编码方式的转换。

比如 `("你好").decode("GB2312")` 将得到 `u'\u4f60\u597d'`，即 `"你"` 和 `“好"` 的 Unicode 码分别是 `0x4f60` 和 `0x597d`，再用 `(u'\u4f60\u597d').encode("UTF-8")` 将得到 `'\xe4\xbd\xa0\xe5\xa5\xbd'`，它是 `“你好”` 的 UTF-8 编码结果。

python 中使用 unicode 的关键：

unicode 是一个类，函数 `unicode(str, "utf8")`从 utf8 编码（当然也可以是别的编码）的字符串 str 生成 unicode 类的对象，函数 `unc.encode("utf8")` 将 unicode 类的对象 unc 转换为（编码为）utf8 编码（当然也可以是别的编码）的字符串。

于是，编写 unicode 相关程序，需要做的事情是：

1. 获取数据（字符串）时，用 `unicode(str, "utf8")` 生成 unicode 对象；
2. 在程序中仅使用 unicode 对象，对程序中出现的字符串常量都以 `u"字符串"` 的形式书写；
3. 输出时，可将 unicode 对象转换为任意编码输出，使用 `str.encode("some_encoding")`。

```python
>>> unicode("你好", "utf8")
u'\u4f60\u597d'
>>> x = _
>>> type(x)
<type 'unicode'>
>>> type("你好")
<type 'str'>
>>> x.encode("utf8")
'\xe4\xbd\xa0\xe5\xa5\xbd'
>>> x.encode("gbk")
'\xc4\xe3\xba\xc3'
>>> x.encode("gb2312")
'\xc4\xe3\xba\xc3'
>>> print x
你好
>>> print x.encode("utf8")
你好
>>> print x.encode("gbk")
???
```

#### python里面基本上要考虑三种编码格式
##### 1、源文件编码
在文件头部使用 `coding声明`，告诉 python 解释器该代码文件所使用的字符集。
```python
#! /usr/bin/python
# coding: utf-8
```

##### 2、内部编码
代码文件中的字符串，经过 `decode` 以后，被转换为统一的 unicode 格式的内部数据，类似于 `u'*'`。unicode 数据可以使用 encode 函数，再自由转换为其他格式的数据，相当于一个统一的平台。

直接输入 `unicode` 数据
```python
>>> u'你好'
u'\u4f60\u597d'
```

将 `unicode` 数据转换为 `gb2312` 格式
```python
>>> u'你好'.encode('gb2312')
'\xc4\xe3\xba\xc3'
```

将输入的 `gb2312` 格式的数据解码为 `unicode`
```python
>>> '你好'.decode('gb2312')
u'\u4f60\u597d'
```

输入数据的格式取决于所用 shell 终端的编码设置，本例中为 `zh_CN`
```shell
[root@chenzheng python]# echo $LANG
zh_CN
```

解码同时转换为 `utf8`
```python
>>> '你好'.decode('gb2312').encode('utf8')
'\xe4\xbd\xa0\xe5\xa5\xbd'
```

##### 3、外部输入的编码
其实这个和在 python 交互 shell 中输入的字符串，所遇到的情况基本一样。但程序中常常用到从网络，文件读取的数据，故此单独列出，需要特别注意其编码格式是否于系统要求相符。

以上内容摘选至：http://www.iteye.com/topic/560229 。


## 附录：如何解决Python2下的编码错误和乱码问题
在使用 Python 2 时，经常会出现一个编码错误和乱码问题，因为在 Python 2 中，`str` 字符串是字节编码而非 Unicode 等编码，再加上该字节编码又不是在所有的平台上都是 UTF 编码（比如在 Windows 上默认是 ASCII 编码）。

在解决 python 2 中的乱码问题时，很多文章都介绍 `在Python源码文件中第一行或第二行注释中指定 coding`（即上面介绍的 `源文件编码`）。但是，笔者好像曾经在 Windows 7 和 Linux Mint 下测试的是该方法无效（笔者重装Windows 7 后，再测试，好像又好了，具体是怎么回事，笔者目前还不清楚；而对于 Linux Mint，因为笔者已经换成 Ubuntu，在写本文时没有再重新测试），在 Ubuntu 12.10 上没有问题。

笔者的测试如下：建立一个py文件（假设名为tests.py），在其中写下下面的代码。
```python
# -*- coding: utf-8 -*-
# 以上是Emacs中的推荐写法（这记录在Python官方的语法文档中）
import  sys
print  sys.getfilesystemencoding()
```

在笔者的使用过程中，发现有两个几乎能够达到 100％ 的解决办法：

（1）使用 sys 标准库中的 `setfilesystemencoding("utf-8")`：
```python
import  sys
reload(sys)  # 一定要有此句，不然，sys 模块中的 setfilesystemencoding 函数不可见，另外，该函数在 Python3 中被移除。
sys.setfilesystemencoding("utf-8")
```

（2）使用 `__future__` 中的 `unicode_literals` 特性：

在每个 `.py` 源码文件中，第一个非注释行（即在所有非注释语句之前）都写上 `from  __future__  import unicode_literals` 一句，此时，将打开 UNICODE 字符串编码，即以前被编码成字节编码的字符串现在都将被作为 UNICODE 字符串来编码。这个特性在 Python 3 中默认被打开，所以在 Python 3 中，普通的字符串都是 UNICODE；而在 Python 2 中，该特性默认关闭，需要手工打开。

另外，建议在打开 `unicode_literals` 特性的同时，也把 `print_function` 和 `division` 特性打开，这样在 Python 2 中，就可以使用 Python 3 中 `print` 和 `//` 的语义。

**总结：**

建议使用第二种方法，因为第二种方法与 Python 3 兼容，更容易将程序移植到 Python 3 中，更容易写兼容 Python 2 和 Python 3 的程序，另外，第一种方法只在 Python 2 中有效，在 Python 3 将出现错误——在 Python 3 中，`sys` 中的 `setfilesystemencoding` 函数被移除。
